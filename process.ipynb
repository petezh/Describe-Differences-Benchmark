{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import itertools\n",
    "import nltk\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/peterzhang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "  - https://github.com/sfu-discourse-lab/SOCC\n",
    "  - https://nextit-public.s3-us-west-2.amazonaws.com/rsics.html#all95data95by95thresholdcsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Deception\n",
    "\n",
    "Downloaded from Rada Mihalcea's [website](https://web.eecs.umich.edu/~mihalcea/downloads.html), based on her open-domain deception paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>_gender</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>country</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_f_l_1</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelors degree</td>\n",
       "      <td>Canada</td>\n",
       "      <td>There is a great deal of truth to the anti-vax...</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_f_l_2</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelors degree</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Jenny mccarthy is a learned doctor who deserve...</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_f_l_3</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelors degree</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Driving doesn't really require any practice.</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_f_l_4</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelors degree</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Drinking and driving is a winning and safe com...</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_f_l_5</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelors degree</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Good hygiene isn't really important or attract...</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id _gender  age         education country  \\\n",
       "0  1_f_l_1  Female   26  Bachelors degree  Canada   \n",
       "1  1_f_l_2  Female   26  Bachelors degree  Canada   \n",
       "2  1_f_l_3  Female   26  Bachelors degree  Canada   \n",
       "3  1_f_l_4  Female   26  Bachelors degree  Canada   \n",
       "4  1_f_l_5  Female   26  Bachelors degree  Canada   \n",
       "\n",
       "                                                text class  \n",
       "0  There is a great deal of truth to the anti-vax...   lie  \n",
       "1  Jenny mccarthy is a learned doctor who deserve...   lie  \n",
       "2       Driving doesn't really require any practice.   lie  \n",
       "3  Drinking and driving is a winning and safe com...   lie  \n",
       "4  Good hygiene isn't really important or attract...   lie  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/OpenDeception/7Truth7LiesDataset.csv'\n",
    "df = pd.read_csv(input_file, quotechar=\"'\", escapechar=\"\\\\\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['lie'] = list(df[df['class']=='lie']['text']) # positive denotes lie\n",
    "data['truth'] = list(df[df['class']=='truth']['text']) # negative denotes truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/open_deception.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake News\n",
    "\n",
    "Downloaded from Rada Mihalcea's [website](https://web.eecs.umich.edu/~mihalcea/downloads.html), based on her fake news paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('data/fakeNewsDatasets/fakeNewsDataset/**/*.txt')\n",
    "legit, fake = [], []\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        contents = f.read()\n",
    "        if 'legit' in file:\n",
    "            legit.append(contents)\n",
    "        else:\n",
    "            fake.append(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['legit'] = legit\n",
    "data['fake'] = fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/fake_news.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Life Deception\n",
    "\n",
    "Downloaded from Rada Mihalcea's [website](https://web.eecs.umich.edu/~mihalcea/downloads.html), based on her real life deception paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('data/RealLifeDeception/Transcription/**/*.txt')\n",
    "truth, lie = [], []\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        contents = f.read().replace('<player>', 'the player')\n",
    "        if 'truth' in file:\n",
    "            truth.extend(contents)\n",
    "        else:\n",
    "            lie.extend(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['truth'] = truth # lie\n",
    "data['lie'] = lie # truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/real_life_deception.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Football\n",
    "\n",
    "Taken from Merullo et al.'s Football Commentary [dataset](https://arxiv.org/abs/1909.03343)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data/football/football_15.json'\n",
    "with open(input_file, 'r') as f:\n",
    "    js_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "white, nonwhite = [], []\n",
    "for instance in js_data.values():\n",
    "    race = instance['label']['race']\n",
    "    commentary = ' '.join(instance['mention'])\n",
    "    if race == 'white':\n",
    "        white.append(commentary)\n",
    "    else:\n",
    "        nonwhite.append(commentary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['white'] = white # white\n",
    "data['nonwhite'] = nonwhite # nonwhite\n",
    "output_file = 'output/football.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Professor Gender\n",
    "\n",
    "Pulled from RateMyProfessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'data/profgender/full-data.txt'\n",
    "df = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['woman'] = list(df[df['Professor Gender']=='W']['Comment Text']) # positive denotes lie\n",
    "data['man'] = list(df[df['Professor Gender']=='M']['Comment Text']) # negative denotes truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/prof_gender.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parenting\n",
    "\n",
    "Read sentences pulled from various parenting topics from [Gao et al.](https://dl.acm.org/doi/10.1145/3411764.3445203)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I participated in the survey re: exclusive ...</td>\n",
       "      <td>1</td>\n",
       "      <td>breastfeeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I've started researching what pumps my insuran...</td>\n",
       "      <td>1</td>\n",
       "      <td>breastfeeding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Three and a half year old while listening to E...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>About a week ago, my 2 1/2 year old started co...</td>\n",
       "      <td>1</td>\n",
       "      <td>economy,child product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When is it positive to say your kid does not l...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  So I participated in the survey re: exclusive ...      1   \n",
       "1  I've started researching what pumps my insuran...      1   \n",
       "2  Three and a half year old while listening to E...      1   \n",
       "3  About a week ago, my 2 1/2 year old started co...      1   \n",
       "4  When is it positive to say your kid does not l...      1   \n",
       "\n",
       "                  topics  \n",
       "0          breastfeeding  \n",
       "1          breastfeeding  \n",
       "2                    NaN  \n",
       "3  economy,child product  \n",
       "4                    NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/parenting/0527_reddit_1300_parenting_clean.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "topics = set(itertools.chain.from_iterable(df['topics'].str.split(',')))\n",
    "data = {}\n",
    "for topic in topics:\n",
    "    data[topic] = list(df[df['topics'].str.contains(topic)]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/parenting.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polarization\n",
    "\n",
    "From Jerry Wei's news slant [dataset](https://github.com/JerryWei03/NewB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "lib_file = 'data/NewB-master/liberal.txt'\n",
    "with open(lib_file, 'r') as file:\n",
    "    data['lib'] = list(map(lambda x: x[2:], file.readlines()))\n",
    "con_file = 'data/NewB-master/conservative.txt'\n",
    "with open(con_file, 'r') as file:\n",
    "    data['con'] = list(map(lambda x: x[2:], file.readlines()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/news_slant.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ukraine Bias\n",
    "\n",
    "Annotated data from [Farber et al.](https://github.com/michaelfaerber/ukraine-news-bias) on news coverage during the Ukraine crisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Russia claims thousands fleeing Ukraine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russia says 143,000 Ukrainians have already le...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thousands of Ukrainians are fleeing across the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the border services, since the be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The head of the citizenship department of the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0            Russia claims thousands fleeing Ukraine  0\n",
       "1  Russia says 143,000 Ukrainians have already le...  0\n",
       "2  Thousands of Ukrainians are fleeing across the...  0\n",
       "3  According to the border services, since the be...  0\n",
       "4  The head of the citizenship department of the ...  0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/ukraine/sentences-with-binary-labels-bias.csv'\n",
    "df = pd.read_csv(input_file, header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['bias'] = list(df[df[1]==1][0])\n",
    "data['no bias'] = list(df[df[1]==0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/ukraine.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essays\n",
    "\n",
    "Automated essay scoring [data](https://www.kaggle.com/c/asap-aes/data?select=training_set_rel3.xlsx) from the Hewlett Foundaiton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "0             NaN             NaN            NaN  ...            NaN   \n",
       "1             NaN             NaN            NaN  ...            NaN   \n",
       "2             NaN             NaN            NaN  ...            NaN   \n",
       "3             NaN             NaN            NaN  ...            NaN   \n",
       "4             NaN             NaN            NaN  ...            NaN   \n",
       "\n",
       "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/papers/training_set_rel3.tsv'\n",
    "df = pd.read_csv(input_file, sep='\\t', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['bad'] = list(df[df['domain1_score'] < 15]['essay'])\n",
    "data['mediocre'] = list(df[(15 <= df['domain1_score']) & (df['domain1_score'] < 25)]['essay'])\n",
    "data['good'] = list(df[(25 <= df['domain1_score']) & (df['domain1_score'] < 35)]['essay'])\n",
    "data['great'] = list(df[35 <= df['domain1_score']]['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/essays.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diplomacy\n",
    "\n",
    "From the [Diplomacy project](https://sites.google.com/view/qanta/projects/diplomacy) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('data/diplomacy/*.txt')\n",
    "data = {}\n",
    "data['truth'] = []\n",
    "data['lie'] = []\n",
    "for file in files:\n",
    "    df = pd.read_json(file, lines=True)\n",
    "    messages = list(itertools.chain.from_iterable(pd.read_json(files[0], lines=True)['messages']))\n",
    "    labels = list(itertools.chain.from_iterable(pd.read_json(files[0], lines=True)['sender_labels']))\n",
    "    df = pd.DataFrame({'message':messages, 'label':labels})\n",
    "    data['truth'].extend(list(df[df['label']==True]['message']))\n",
    "    data['lie'].extend(list(df[df['label']==False]['message']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/diplomacy.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Headlines\n",
    "\n",
    "From the ABC \"million news headlines\" [dataset](https://www.kaggle.com/therohk/million-headlines), \"spam clickbait catalog\" [dataset](https://www.kaggle.com/therohk/examine-the-examiner), and India news headlines [dataset](https://www.kaggle.com/therohk/india-headlines-news-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_files = [\n",
    "    ('data/abc_headlines/abcnews-date-text.csv', 'output/abc_headlines.json'),\n",
    "    ('data/examiner_headlines/examiner-date-text.csv', 'output/examiner_headlines.json'),\n",
    "    ('data/india_headlines/india-news-headlines.csv', 'output/india_headlines.json')\n",
    "]\n",
    "for input_file, output_file in headline_files:\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['year'] = df['publish_date'].astype(str).str[:4].astype(int)\n",
    "    data = {}\n",
    "    for year in df['year'].unique():\n",
    "        data[str(year)] = list(df[df['year']==year]['headline_text'])\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Relevance\n",
    "\n",
    "From the \"Home Depot Product Search Relevance\" [dataset](https://www.kaggle.com/c/home-depot-product-search-relevance/data?select=train.csv.zip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>product_uid</th>\n",
       "      <th>product_title</th>\n",
       "      <th>search_term</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>angle bracket</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>100001</td>\n",
       "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
       "      <td>l bracket</td>\n",
       "      <td>2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>100002</td>\n",
       "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
       "      <td>deck over</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>rain shower head</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>100005</td>\n",
       "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
       "      <td>shower only faucet</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  product_uid                                      product_title  \\\n",
       "0   2       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "1   3       100001                  Simpson Strong-Tie 12-Gauge Angle   \n",
       "2   9       100002  BEHR Premium Textured DeckOver 1-gal. #SC-141 ...   \n",
       "3  16       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "4  17       100005  Delta Vero 1-Handle Shower Only Faucet Trim Ki...   \n",
       "\n",
       "          search_term  relevance  \n",
       "0       angle bracket       3.00  \n",
       "1           l bracket       2.50  \n",
       "2           deck over       3.00  \n",
       "3    rain shower head       2.33  \n",
       "4  shower only faucet       2.67  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/search_relevance/train.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['low relevance'] = list(df[df['relevance'] < 2.5]['search_term'])\n",
    "data['high relevance'] = list(df[df['relevance'] >= 2.5]['search_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/search_relevance.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Reviews\n",
    "\n",
    "Reviews of products from Jianmo Ni's [Amazon Review Data](https://nijianmo.github.io/amazon/index.html#complete-data) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/amazon_reviews/AMAZON_FASHION_5.json\n",
      "data/amazon_reviews/All_Beauty_5.json\n",
      "data/amazon_reviews/Appliances_5.json\n",
      "data/amazon_reviews/Arts_Crafts_and_Sewing_5.json\n",
      "data/amazon_reviews/Cell_Phones_and_Accessories_5.json\n"
     ]
    }
   ],
   "source": [
    "review_files = [\n",
    "    ('data/amazon_reviews/AMAZON_FASHION_5.json','output/amazon_fashion_reviews.json'),\n",
    "    ('data/amazon_reviews/All_Beauty_5.json','output/beauty_reviews.json'),\n",
    "    ('data/amazon_reviews/Appliances_5.json','output/appliances_reviews.json'),\n",
    "    ('data/amazon_reviews/Arts_Crafts_and_Sewing_5.json','output/arts_crafts_reviews.json'),\n",
    "    ('data/amazon_reviews/Cell_Phones_and_Accessories_5.json','output/phone_reviews.json'),\n",
    "    ('data/amazon_reviews/Automotive_5.json','output/automotive_reviews.json')\n",
    "]\n",
    "for input_file, output_file in review_files:\n",
    "    print(input_file)\n",
    "    df = pd.read_json(input_file, lines=True)\n",
    "    data = {}\n",
    "    for rating in df['overall'].unique():\n",
    "        data[str(rating)] = list(df[df['overall'] == rating]['reviewText'].astype(str))\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mafia Deception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>scum</th>\n",
       "      <th>slot_id</th>\n",
       "      <th>words</th>\n",
       "      <th>wc</th>\n",
       "      <th>punc</th>\n",
       "      <th>...</th>\n",
       "      <th>neg_em_ratio</th>\n",
       "      <th>not_ratio</th>\n",
       "      <th>anger_ratio</th>\n",
       "      <th>sensory_ratio</th>\n",
       "      <th>cog_ratio</th>\n",
       "      <th>insight_ratio</th>\n",
       "      <th>motion_ratio</th>\n",
       "      <th>tent_ratio</th>\n",
       "      <th>spp_ratio</th>\n",
       "      <th>quant_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28480</td>\n",
       "      <td>ThAdmiral</td>\n",
       "      <td>yep /!@ \\nWhat if he is scum? This option woul...</td>\n",
       "      <td>2013-05-15 01:44:00</td>\n",
       "      <td>2013-07-22 00:17:00</td>\n",
       "      <td>False</td>\n",
       "      <td>240</td>\n",
       "      <td>[yep, what, if, he, is, scum, this, option, wo...</td>\n",
       "      <td>2688</td>\n",
       "      <td>[/!@, ?, ', ., :, ', ., /!@, ., ., ., /!@, (, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.018601</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.081101</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.029762</td>\n",
       "      <td>0.012649</td>\n",
       "      <td>0.013393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5845</td>\n",
       "      <td>Khelvaster</td>\n",
       "      <td>[s]Gah...I don't know anyone. Vote: SPAG, sinc...</td>\n",
       "      <td>2007-08-02 16:33:00</td>\n",
       "      <td>2007-08-27 20:07:00</td>\n",
       "      <td>False</td>\n",
       "      <td>5210</td>\n",
       "      <td>[s, gah, i, don, t, know, anyone, vote, spag, ...</td>\n",
       "      <td>863</td>\n",
       "      <td>[[, ], ..., ', ., :, ,, ', .[/, ], ,, ', ..., ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006952</td>\n",
       "      <td>0.031286</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.077636</td>\n",
       "      <td>0.017381</td>\n",
       "      <td>0.006952</td>\n",
       "      <td>0.034762</td>\n",
       "      <td>0.027810</td>\n",
       "      <td>0.015064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30779</td>\n",
       "      <td>Elyse</td>\n",
       "      <td>/confirm /!@ ANNOUNCEMENT\\nThere are NO jester...</td>\n",
       "      <td>2013-08-13 15:28:00</td>\n",
       "      <td>2013-10-11 00:52:00</td>\n",
       "      <td>False</td>\n",
       "      <td>447</td>\n",
       "      <td>[confirm, announcement, there, are, no, jester...</td>\n",
       "      <td>3194</td>\n",
       "      <td>[/, /!@, ,, ., ', !, /!@, ., :, /!@, ', /!@, '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.028491</td>\n",
       "      <td>0.100188</td>\n",
       "      <td>0.027552</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.029430</td>\n",
       "      <td>0.011271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10744</td>\n",
       "      <td>Simpor</td>\n",
       "      <td>/confirm /!@ Vote: AWA\\n\\nFor being the last o...</td>\n",
       "      <td>2009-03-04 21:42:00</td>\n",
       "      <td>2009-03-14 21:23:00</td>\n",
       "      <td>True</td>\n",
       "      <td>6238</td>\n",
       "      <td>[confirm, vote, awa, for, being, the, last, on...</td>\n",
       "      <td>154</td>\n",
       "      <td>[/, /!@, :, .., /!@, ,, ?, !, /!@, ', ,, ., ',...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.038961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10617</td>\n",
       "      <td>blakebowling</td>\n",
       "      <td>Confirm /!@ Vote: blakebowling /!@ Unvote, Vot...</td>\n",
       "      <td>2009-02-20 02:08:00</td>\n",
       "      <td>2009-03-01 03:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>6200</td>\n",
       "      <td>[confirm, vote, blakebowling, unvote, vote, at...</td>\n",
       "      <td>239</td>\n",
       "      <td>[/!@, :, /!@, ,, :, ., ', ., /!@, /!@, ,, .[/,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025105</td>\n",
       "      <td>0.037657</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.050209</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>0.016736</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id        author                                            content  \\\n",
       "0    28480     ThAdmiral  yep /!@ \\nWhat if he is scum? This option woul...   \n",
       "1     5845    Khelvaster  [s]Gah...I don't know anyone. Vote: SPAG, sinc...   \n",
       "2    30779         Elyse  /confirm /!@ ANNOUNCEMENT\\nThere are NO jester...   \n",
       "3    10744        Simpor  /confirm /!@ Vote: AWA\\n\\nFor being the last o...   \n",
       "4    10617  blakebowling  Confirm /!@ Vote: blakebowling /!@ Unvote, Vot...   \n",
       "\n",
       "          inserted_at          updated_at   scum  slot_id  \\\n",
       "0 2013-05-15 01:44:00 2013-07-22 00:17:00  False      240   \n",
       "1 2007-08-02 16:33:00 2007-08-27 20:07:00  False     5210   \n",
       "2 2013-08-13 15:28:00 2013-10-11 00:52:00  False      447   \n",
       "3 2009-03-04 21:42:00 2009-03-14 21:23:00   True     6238   \n",
       "4 2009-02-20 02:08:00 2009-03-01 03:10:00  False     6200   \n",
       "\n",
       "                                               words    wc  \\\n",
       "0  [yep, what, if, he, is, scum, this, option, wo...  2688   \n",
       "1  [s, gah, i, don, t, know, anyone, vote, spag, ...   863   \n",
       "2  [confirm, announcement, there, are, no, jester...  3194   \n",
       "3  [confirm, vote, awa, for, being, the, last, on...   154   \n",
       "4  [confirm, vote, blakebowling, unvote, vote, at...   239   \n",
       "\n",
       "                                                punc  ...  neg_em_ratio  \\\n",
       "0  [/!@, ?, ', ., :, ', ., /!@, ., ., ., /!@, (, ...  ...      0.013393   \n",
       "1  [[, ], ..., ', ., :, ,, ', .[/, ], ,, ', ..., ...  ...      0.006952   \n",
       "2  [/, /!@, ,, ., ', !, /!@, ., :, /!@, ', /!@, '...  ...      0.017533   \n",
       "3  [/, /!@, :, .., /!@, ,, ?, !, /!@, ', ,, ., ',...  ...      0.006494   \n",
       "4  [/!@, :, /!@, ,, :, ., ', ., /!@, /!@, ,, .[/,...  ...      0.025105   \n",
       "\n",
       "   not_ratio  anger_ratio  sensory_ratio  cog_ratio  insight_ratio  \\\n",
       "0   0.018601     0.005952       0.017857   0.081101       0.024926   \n",
       "1   0.031286     0.001159       0.016222   0.077636       0.017381   \n",
       "2   0.033500     0.003444       0.028491   0.100188       0.027552   \n",
       "3   0.025974     0.006494       0.012987   0.090909       0.019481   \n",
       "4   0.037657     0.008368       0.016736   0.050209       0.012552   \n",
       "\n",
       "   motion_ratio  tent_ratio  spp_ratio  quant_ratio  \n",
       "0      0.004836    0.029762   0.012649     0.013393  \n",
       "1      0.006952    0.034762   0.027810     0.015064  \n",
       "2      0.005322    0.022855   0.029430     0.011271  \n",
       "3      0.000000    0.032468   0.012987     0.038961  \n",
       "4      0.020921    0.020921   0.016736     0.000000  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/mafia/docs.pkl'\n",
    "df = pd.read_pickle(input_file, 'gzip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['scum'] = list(df[df['scum']]['content'])\n",
    "data['not scum'] = list(df[~df['scum']]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/mafia_deception.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks Reddit\n",
    "\n",
    "From [\"Daily News for Stock Market Prediction.\"](https://www.kaggle.com/datasets/aaron7sun/stocknews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Elephants extinct by 2020?'</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1  b'An American citizen living in S.Ossetia blam...  ...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n",
       "3             b'Russian forces sink Georgian ships '  ...   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "2  b'U.S. troops still in Georgia (did you know t...   \n",
       "3                      b'Elephants extinct by 2020?'   \n",
       "4  b'Bank analyst forecast Georgian crisis 2 days...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2       b'Why Russias response to Georgia was right'   \n",
       "3  b'US humanitarian missions soon in Georgia - i...   \n",
       "4  b\"Georgia confict could set back Russia's US r...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "2  b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3             b\"Georgia's DDOS came from US sources\"   \n",
       "4  b'War in the Caucasus is as much the product o...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'data/stocks_reddit/Combined_News_DJIA.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['down'] = []\n",
    "data['up'] = []\n",
    "for col in df.columns:\n",
    "    if \"Top\" in col:\n",
    "        data['down'].extend(list(df[df['Label'] == 0][col]))\n",
    "        data['up'].extend(list(df[df['Label'] == 1][col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/reddit_stocks.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unhealthy Conversations\n",
    "\n",
    "From the [Unhealthy Comments Corpus](https://github.com/conversationai/unhealthy-conversations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('data/unhealthy_convo/*.csv')\n",
    "data = defaultdict(list)\n",
    "attributes = ['antagonize', 'condescending', 'dismissive', 'generalisation', 'generalisation_unfair', 'healthy', 'hostile', 'sarcastic']\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    for attr in attributes:\n",
    "        data[attr].extend(list(df[df[attr] == 1]['comment']))\n",
    "        data['not_' + attr].extend(list(df[df[attr] == 0]['comment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'output/unhealthy_convo.json'\n",
    "with open(output_file, 'w') as outfile:\n",
    "    json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
