{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filepath):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'output/prof_gender.json'\n",
    "distributions = json.load(open(filepath, 'r'))['distributions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/peterzhang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['woman', 'man'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = distributions['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jans', 'is', 'great', 'she', 'is', 'fantastic', 'teacher', 'and', 'her', 'class', 'was', 'both', 'interesting', 'and', 'lively', 'she', 'does', 'expect', 'you', 'to', 'read', 'lot', 'out', 'of', 'the', 'book', 'and', 'other', 'sources', 'as', 'well', 'she', 'is', 'very', 'lively', 'teacher', 'and', 'you', 'can', 'tell', 'she', 'loves', 'the', 'subject', 'she', 'teaches']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from en-core-web-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: jinja2 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.59.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: click<8.1.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/peterzhang/opt/anaconda3/lib/python3.8/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['great', 'fantastic', 'teacher', 'class', 'interesting', 'lively', 'expect', 'read', 'lot', 'book', 'source', 'well', 'lively', 'teacher', 'tell', 'love', 'teach']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.042*\"ever\" + 0.038*\"way\" + 0.034*\"think\" + 0.034*\"bad\" + 0.029*\"math\" + '\n",
      "  '0.018*\"people\" + 0.015*\"day\" + 0.015*\"seem\" + 0.014*\"life\" + 0.013*\"rude\"'),\n",
      " (1,\n",
      "  '0.055*\"professor\" + 0.054*\"great\" + 0.053*\"teacher\" + 0.052*\"student\" + '\n",
      "  '0.039*\"help\" + 0.034*\"learn\" + 0.028*\"love\" + 0.025*\"always\" + 0.021*\"fun\" '\n",
      "  '+ 0.021*\"want\"'),\n",
      " (2,\n",
      "  '0.032*\"look\" + 0.026*\"art\" + 0.025*\"fine\" + 0.019*\"college\" + '\n",
      "  '0.017*\"probably\" + 0.017*\"school\" + 0.016*\"spanish\" + 0.015*\"chapter\" + '\n",
      "  '0.014*\"suffer\" + 0.014*\"communicate\"'),\n",
      " (3,\n",
      "  '0.040*\"lady\" + 0.032*\"ready\" + 0.022*\"hate\" + 0.022*\"issue\" + 0.018*\"other\" '\n",
      "  '+ 0.017*\"spend\" + 0.017*\"catch\" + 0.015*\"waste\" + 0.015*\"back\" + '\n",
      "  '0.014*\"writing\"'),\n",
      " (4,\n",
      "  '0.086*\"class\" + 0.036*\"take\" + 0.023*\"make\" + 0.021*\"test\" + 0.018*\"good\" + '\n",
      "  '0.018*\"get\" + 0.018*\"easy\" + 0.016*\"work\" + 0.015*\"go\" + 0.015*\"really\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.758948353834929\n",
      "\n",
      "Coherence Score:  0.35368732250932094\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el912761402243628538722351941816\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el912761402243628538722351941816_data = {\"mdsDat\": {\"x\": [0.3571326620569117, 0.12283006526499164, -0.17361358170456795, -0.15297752046613702, -0.15337162515119873], \"y\": [-0.18467672729570755, 0.33148640449293326, -0.13450229894702764, -0.003638450847824312, -0.008668927402373914], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [61.43129117568462, 18.46855079533828, 11.01735504828169, 4.592844874777508, 4.489958105917898]}, \"tinfo\": {\"Term\": [\"class\", \"professor\", \"great\", \"teacher\", \"student\", \"help\", \"learn\", \"ever\", \"take\", \"way\", \"love\", \"think\", \"bad\", \"always\", \"math\", \"make\", \"fun\", \"want\", \"test\", \"care\", \"lady\", \"get\", \"easy\", \"look\", \"work\", \"teach\", \"people\", \"ready\", \"go\", \"amazing\", \"class\", \"test\", \"get\", \"easy\", \"make\", \"work\", \"go\", \"give\", \"grade\", \"hard\", \"time\", \"lot\", \"know\", \"read\", \"nice\", \"take\", \"question\", \"lecture\", \"tough\", \"paper\", \"need\", \"interesting\", \"never\", \"talk\", \"also\", \"book\", \"point\", \"even\", \"come\", \"expect\", \"material\", \"understand\", \"really\", \"good\", \"helpful\", \"much\", \"teach\", \"well\", \"teacher\", \"great\", \"student\", \"learn\", \"love\", \"always\", \"fun\", \"professor\", \"care\", \"amazing\", \"woman\", \"excellent\", \"project\", \"enjoy\", \"effort\", \"person\", \"lecturer\", \"willing\", \"challenge\", \"wonderful\", \"definitely\", \"different\", \"nursing\", \"favorite\", \"see\", \"topic\", \"actually\", \"job\", \"passionate\", \"skip\", \"relevant\", \"help\", \"teacher\", \"want\", \"teach\", \"well\", \"good\", \"course\", \"ever\", \"bad\", \"think\", \"math\", \"people\", \"day\", \"seem\", \"opinion\", \"able\", \"base\", \"simple\", \"far\", \"smart\", \"lab\", \"english\", \"highly\", \"hilarious\", \"interested\", \"thank\", \"around\", \"beware\", \"cool\", \"creativity\", \"highly_recommend\", \"speech\", \"pay_attention\", \"midterm\", \"assign\", \"bore\", \"buy\", \"patience\", \"rude\", \"life\", \"way\", \"funny\", \"look\", \"art\", \"fine\", \"college\", \"school\", \"probably\", \"spanish\", \"chapter\", \"bring\", \"year\", \"communicate\", \"suffer\", \"feedback\", \"especially\", \"confuse\", \"lesson\", \"classroom\", \"hear\", \"annoying\", \"old\", \"improve\", \"language\", \"thought\", \"act\", \"child\", \"incredible\", \"top\", \"career\", \"accessible\", \"view\", \"motivating\", \"lady\", \"ready\", \"hate\", \"issue\", \"other\", \"spend\", \"catch\", \"waste\", \"back\", \"writing\", \"unclear\", \"leave\", \"watch\", \"soon\", \"easily\", \"history\", \"meet\", \"fairly\", \"idea\", \"new\", \"movie\", \"half\", \"complete\", \"arrogant\", \"comment\", \"money\", \"personality\", \"professional\", \"obviously\", \"requirement\", \"power_point\"], \"Freq\": [5449.0, 1038.0, 1032.0, 1416.0, 981.0, 825.0, 644.0, 476.0, 2296.0, 480.0, 540.0, 386.0, 384.0, 482.0, 333.0, 1479.0, 400.0, 503.0, 1323.0, 368.0, 185.0, 1156.0, 1152.0, 154.0, 1015.0, 763.0, 209.0, 147.0, 925.0, 250.0, 5449.08338488957, 1322.3724557921287, 1156.1947160295992, 1152.04819483209, 1478.664227721157, 1015.1512631333464, 925.0326264493228, 843.5929464800269, 838.4831680896299, 836.1837325384193, 815.2318891197041, 789.6365510506305, 714.4728585585309, 625.4469402697108, 592.0691731308283, 2293.9713713090555, 506.8492495709378, 488.4424475947472, 441.79808201639173, 429.74190466378246, 417.5286924013708, 395.3783039915538, 388.38334238033485, 382.0527660174209, 380.93338519930643, 374.476669413337, 362.58249494128205, 360.2010731745269, 354.28060426699557, 339.93804331000314, 647.3060703705943, 652.7566691923371, 923.633363681334, 1167.7211136846308, 464.5236673711927, 491.2671358169331, 490.09457713437973, 422.43025696433784, 408.79826280624934, 1032.1966107243395, 981.2618509039569, 643.4115907828836, 539.7912672072022, 482.2756593539484, 399.6176486852938, 1036.4659606310108, 367.68303723115287, 249.61425959447493, 237.9072540475157, 224.17894258268186, 218.1284580169205, 214.19963942256473, 209.14973292484382, 199.94236083514886, 214.47192660548905, 170.96697461564315, 170.2519578411649, 159.01209140212563, 153.73397978796615, 151.5029040364696, 151.70666428604775, 133.74468923861434, 132.60584654944927, 129.0380006907814, 124.65837491690698, 95.15212148574659, 86.97553446153559, 93.29849180031671, 76.48715766954606, 742.6206322169779, 1006.8317825983304, 396.10511751269934, 272.7017558470976, 244.1847948386484, 174.12016801291455, 136.23993039695253, 476.0359242688229, 383.3152182393854, 385.60594772745713, 332.7479331178561, 208.4726424357108, 171.0333781573963, 167.4642804925814, 133.24895236253866, 129.64188534928718, 127.87708563924065, 123.83640255125815, 117.13599876483501, 118.16574731736651, 108.5996752308189, 105.80948168662589, 91.1416197695475, 89.92997473551654, 78.32312661531645, 83.36836837151637, 80.77037290655194, 78.45827577487935, 73.45464635791994, 83.76561780288225, 71.85752966597592, 70.7355570351049, 69.08081149731801, 68.4403673875251, 67.69699165333951, 66.67952699165185, 61.569496937349015, 72.42519831258934, 146.26124102901363, 156.55249498395193, 435.2963844690955, 88.30146822121881, 153.262836496868, 122.43779435969934, 116.18083428217787, 92.00605835978976, 78.96147074080021, 79.48855142578435, 74.4712190804153, 69.50325329696712, 64.86760522172877, 63.73825336042233, 65.14097404186798, 65.45451390727432, 53.440131842878756, 52.84553531860116, 48.81629464395431, 45.49462963534023, 43.53390109148408, 39.72927365823667, 39.2800559665627, 38.63977636170067, 38.5175841210419, 37.710884126108944, 35.54123889437658, 34.050116858637296, 33.0321287698842, 32.434525680888065, 31.92102728388678, 28.847208262022775, 33.85766374993255, 26.395236053869944, 28.65739908413411, 184.28561638842118, 146.45629424843054, 103.75335293146311, 99.21965116637804, 85.31774921314829, 80.5096177657077, 79.29433910815888, 69.2552291627824, 68.88592821450169, 63.398000617133704, 62.39398004667065, 59.913108044884105, 56.002162789184226, 62.95926290890713, 54.77507571426236, 49.329169410013414, 46.779797415015835, 46.87386942124982, 45.65104076758585, 38.747774655450165, 36.3008153283027, 34.26856650205231, 32.34151915838097, 31.269561514166803, 29.759884573268057, 28.839363006511185, 27.087628549297644, 23.916054370184575, 23.545990687521144, 22.48550199016604, 22.556629657039238], \"Total\": [5449.0, 1038.0, 1032.0, 1416.0, 981.0, 825.0, 644.0, 476.0, 2296.0, 480.0, 540.0, 386.0, 384.0, 482.0, 333.0, 1479.0, 400.0, 503.0, 1323.0, 368.0, 185.0, 1156.0, 1152.0, 154.0, 1015.0, 763.0, 209.0, 147.0, 925.0, 250.0, 5449.7938935433785, 1323.0828711462866, 1156.9028561988348, 1152.756463240986, 1479.5788172415241, 1015.9007971377393, 925.7430119026096, 844.302803618079, 839.1913968940587, 836.8901558695948, 815.9434259633617, 790.345579700064, 715.180570931217, 626.1565588832278, 592.7770778720743, 2296.999473864261, 507.5585019671983, 489.1531143939502, 442.52371124429703, 430.44918473585017, 418.23734001265296, 396.0880601901589, 389.09152678342264, 382.76269773311225, 381.64538127399175, 375.18451357339774, 363.29669634491694, 360.9120631090555, 354.99551540012004, 340.65097241286895, 658.1925796823406, 664.108049800866, 999.5849160691403, 1342.3631912720016, 484.7013537769609, 575.6239561655061, 763.3199674654492, 667.1373629657178, 1416.1516897937622, 1032.91751682628, 981.9826225360548, 644.1306151835206, 540.5115294651196, 482.9982403398819, 400.33671123223934, 1038.3912386891054, 368.40482735402185, 250.3388381367275, 238.63370353836376, 224.9065731085366, 218.85807649652293, 214.919413584784, 209.8879601551522, 200.6608750680818, 215.2837250829616, 171.68132168274172, 170.98163298607125, 159.7283402910022, 154.45469064987333, 152.23331495933198, 152.51467529901635, 134.46342673613563, 133.32701334591223, 129.7577748182998, 125.37873132513285, 95.87505427873465, 87.69400443628257, 94.1456038314607, 77.29695593410271, 825.5838594268612, 1416.1516897937622, 503.4541587718036, 763.3199674654492, 667.1373629657178, 1342.3631912720016, 350.3269301864809, 476.75591274927865, 384.0343044833438, 386.3299837341285, 333.47673700238454, 209.19200719102503, 171.75585143286995, 168.18340978630377, 133.97912534122997, 130.37801565923695, 128.6099596116896, 124.56752334867925, 117.85820264132606, 118.89974997760991, 109.32383458759061, 106.52727786701914, 91.89798278196712, 90.70028676421231, 79.04614195263395, 84.1411116149746, 81.54794915597303, 79.22700769042504, 74.17745058022496, 84.5955484344199, 72.58480216938455, 71.45557079232317, 69.80321275797782, 69.170863106466, 68.42014542926017, 67.39896044690275, 62.297042829907674, 73.38937505340581, 149.42297655420057, 160.6804968335008, 480.3532377796068, 166.92325528982494, 154.0177898268048, 123.19217667261326, 116.91902994367298, 92.74112877390492, 79.69850392933874, 80.23080403208881, 75.20918063396188, 70.24494672229915, 65.6056453004028, 64.46843214438947, 66.0387907451086, 66.36249373275015, 54.18428845491836, 53.584219249061704, 49.559896884447845, 46.24833921584091, 44.27623617708487, 40.46945380788445, 40.030782633414574, 39.37830304080141, 39.263449514493026, 38.44818811426184, 36.28853507922766, 34.7832853489496, 33.77687010776344, 33.18752788319705, 32.672798558161006, 29.58753679042565, 34.77112638239658, 27.129442092032637, 65.10489025964307, 185.0291226622621, 147.27095258964272, 104.49484347860275, 100.00830731852808, 86.0983865611285, 81.25658911718945, 80.07163815386308, 69.99844031029448, 69.63105341207901, 64.13637972273959, 63.137049999580775, 60.66177046970812, 56.74822033355494, 63.8113806703756, 55.52439846654169, 50.07080870727972, 47.51697168404305, 47.619863738877704, 46.39156433129951, 39.49247125726554, 37.038161142245414, 35.00902984599837, 33.08135179531664, 32.01698684433282, 30.4954539950495, 29.57998239722868, 27.827914155028196, 24.657809049967035, 24.29025663833754, 23.2343866496323, 23.34599451500537], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.4497, -3.8657, -4.0, -4.0036, -3.754, -4.1301, -4.2231, -4.3152, -4.3213, -4.3241, -4.3494, -4.3813, -4.4814, -4.6145, -4.6693, -3.3149, -4.8247, -4.8617, -4.9621, -4.9897, -5.0186, -5.0731, -5.0909, -5.1074, -5.1103, -5.1274, -5.1597, -5.1663, -5.1828, -5.2242, -4.5801, -4.5717, -4.2246, -3.9901, -4.9119, -4.8559, -4.8583, -5.0069, -5.0397, -2.9116, -2.9622, -3.3843, -3.5599, -3.6726, -3.8606, -2.9075, -3.9438, -4.3312, -4.3792, -4.4386, -4.466, -4.4842, -4.508, -4.553, -4.4829, -4.7096, -4.7138, -4.7821, -4.8158, -4.8305, -4.8291, -4.9551, -4.9637, -4.991, -5.0255, -5.2956, -5.3854, -5.3153, -5.5139, -3.2409, -2.9365, -3.8694, -4.2427, -4.3531, -4.6913, -4.9367, -3.169, -3.3856, -3.3797, -3.5271, -3.9947, -4.1926, -4.2137, -4.4423, -4.4697, -4.4834, -4.5155, -4.5711, -4.5624, -4.6468, -4.6728, -4.8221, -4.8354, -4.9736, -4.9112, -4.9429, -4.9719, -5.0378, -4.9064, -5.0598, -5.0755, -5.0992, -5.1085, -5.1194, -5.1346, -5.2143, -5.0519, -4.3491, -4.2811, -3.2584, -4.8537, -3.4273, -3.6519, -3.7044, -3.9376, -4.0905, -4.0839, -4.1491, -4.2181, -4.2872, -4.3047, -4.2829, -4.2781, -4.4809, -4.4921, -4.5714, -4.6419, -4.686, -4.7774, -4.7888, -4.8052, -4.8084, -4.8296, -4.8888, -4.9317, -4.962, -4.9803, -4.9962, -5.0975, -4.9373, -5.1863, -5.1041, -3.2204, -3.4501, -3.7948, -3.8395, -3.9905, -4.0485, -4.0637, -4.199, -4.2044, -4.2874, -4.3034, -4.3439, -4.4115, -4.2944, -4.4336, -4.5383, -4.5914, -4.5894, -4.6158, -4.7798, -4.845, -4.9026, -4.9605, -4.9942, -5.0437, -5.0751, -5.1378, -5.2623, -5.2779, -5.324, -5.3208], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4871, 0.4867, 0.4866, 0.4866, 0.4866, 0.4865, 0.4865, 0.4864, 0.4864, 0.4864, 0.4864, 0.4864, 0.4863, 0.4861, 0.4861, 0.4859, 0.4859, 0.4858, 0.4856, 0.4856, 0.4856, 0.4855, 0.4854, 0.4854, 0.4854, 0.4854, 0.4853, 0.4853, 0.4852, 0.4852, 0.4706, 0.47, 0.4082, 0.3479, 0.4447, 0.3288, 0.0442, 0.0303, -0.7552, 1.6884, 1.6884, 1.688, 1.6878, 1.6876, 1.6873, 1.6872, 1.6871, 1.6862, 1.6861, 1.6859, 1.6858, 1.6857, 1.6856, 1.6855, 1.6853, 1.6849, 1.6848, 1.6846, 1.6844, 1.6843, 1.6838, 1.6837, 1.6837, 1.6835, 1.6833, 1.6815, 1.6809, 1.6801, 1.6786, 1.5832, 1.348, 1.4493, 0.6598, 0.684, -0.3533, 0.7447, 2.2042, 2.2038, 2.2038, 2.2035, 2.2023, 2.2015, 2.2014, 2.2002, 2.2, 2.2, 2.1998, 2.1996, 2.1995, 2.1991, 2.1989, 2.1974, 2.1972, 2.1965, 2.1965, 2.1961, 2.1959, 2.1959, 2.1958, 2.1956, 2.1956, 2.1953, 2.1951, 2.1951, 2.195, 2.194, 2.1925, 2.1843, 2.1797, 2.1072, 1.5689, 3.0758, 3.0745, 3.0743, 3.0727, 3.0714, 3.0714, 3.0708, 3.0701, 3.0694, 3.0693, 3.067, 3.0669, 3.0668, 3.0668, 3.0656, 3.0642, 3.0638, 3.0622, 3.0617, 3.0617, 3.0615, 3.0613, 3.0599, 3.0594, 3.0584, 3.0577, 3.0574, 3.0553, 3.054, 3.0532, 2.2601, 3.0993, 3.0978, 3.0962, 3.0954, 3.0942, 3.0941, 3.0936, 3.0927, 3.0926, 3.0917, 3.0915, 3.0909, 3.0901, 3.0899, 3.0897, 3.0884, 3.0877, 3.0875, 3.0872, 3.0843, 3.0832, 3.0819, 3.0807, 3.0797, 3.0789, 3.078, 3.0764, 3.0728, 3.0722, 3.0706, 3.0689]}, \"token.table\": {\"Topic\": [3, 4, 4, 2, 1, 2, 2, 4, 3, 5, 4, 3, 5, 3, 3, 3, 1, 3, 4, 3, 2, 4, 5, 2, 4, 4, 1, 4, 4, 1, 5, 4, 5, 4, 3, 1, 2, 3, 3, 2, 2, 5, 1, 2, 3, 2, 4, 1, 3, 2, 1, 5, 3, 2, 4, 4, 2, 1, 3, 1, 1, 1, 1, 2, 1, 2, 5, 1, 5, 4, 1, 2, 1, 2, 3, 3, 3, 5, 5, 4, 4, 3, 1, 5, 2, 1, 3, 5, 4, 2, 5, 1, 2, 4, 2, 3, 4, 1, 2, 1, 1, 2, 3, 5, 3, 5, 1, 2, 3, 4, 5, 5, 1, 2, 1, 1, 5, 1, 2, 5, 4, 3, 5, 1, 2, 3, 3, 3, 2, 5, 1, 5, 4, 5, 1, 2, 2, 1, 1, 5, 1, 2, 2, 5, 1, 3, 4, 2, 3, 3, 2, 3, 5, 4, 3, 5, 2, 4, 1, 2, 1, 1, 2, 1, 2, 1, 3, 3, 4, 1, 4, 2, 1, 5, 1, 2, 4, 1, 2, 5, 5, 1, 3, 1, 2, 2, 2, 2, 1, 5, 4], \"Freq\": [0.9971006180963441, 0.9778227954448155, 0.9774809842977282, 0.9969793016636074, 0.9983089503878251, 0.9979332422843209, 0.99864648194723, 0.9742502502922799, 0.9932806506890198, 0.9682360226689217, 0.9903226267705173, 0.9938593315371631, 0.9909371841849869, 0.9973067393426343, 0.9952572910097225, 0.9845127599010238, 0.9968428505694013, 0.9940806142371135, 0.9907683965666431, 0.9952318309760111, 0.9989011345021469, 0.9801424229875138, 0.9866165076852325, 0.994258839566989, 0.9965129630851953, 0.9769999379668727, 0.9998543259508733, 0.9937610736382368, 0.9920086289254498, 0.9971956958414024, 0.9837531851426141, 0.9842699914188611, 0.9673123455774341, 0.9887026220866988, 0.9841265698535768, 0.6108579773929644, 0.38820880806281854, 0.9929600499619483, 0.9955992682254242, 0.9970561551225139, 0.9984673856744544, 0.9905555308832803, 0.9993437787901365, 0.995769361165377, 0.9950503018796992, 0.9957220542832846, 0.9890971771680347, 0.9974728938090941, 0.9984144659162808, 0.9959691124363044, 0.9980890340389812, 0.9869830845741872, 0.9927183460964716, 0.9965535108885405, 0.9781433236702242, 0.9921396034151521, 0.9991589299137645, 0.4672806066750282, 0.5271883767615703, 0.999219592039213, 0.9996413566118916, 0.9991973885915891, 0.8701072910776272, 0.1296221478146465, 0.9985803037322973, 0.999111723045322, 0.971178011774762, 0.998936352801677, 0.9952644220314654, 0.9883997987688931, 0.09932364721486468, 0.8999691448859081, 0.9593536233735658, 0.04126252143542218, 0.99022848211916, 0.9919431871148474, 0.9922791119058664, 0.9786141119960774, 0.991559579054002, 0.9932902096542542, 0.9642176456355371, 0.986765426790079, 0.9972529841226809, 0.989917764378147, 0.9908729722729477, 0.9983492687312804, 0.9970378409354901, 0.9944380503595611, 0.9883430628010377, 0.998244742359904, 0.9890908151116595, 0.9976426309880928, 0.994037054670682, 0.9730079125649267, 0.02489412267715883, 0.9770943150784841, 0.9933917385261188, 0.9995627486140997, 0.9990536196968347, 0.9996087959392368, 0.982994977415664, 0.015193121752946893, 0.9985704040207725, 0.9891202729104756, 0.9830728856937373, 0.9803927402849631, 0.07679914642447955, 0.24575726855833452, 0.1535982928489591, 0.44543504926198135, 0.09215897570937545, 0.9719704998782649, 0.8529874317093664, 0.14592860338816047, 0.999432523139503, 0.9971946786082797, 0.9875299964376136, 0.9986890892021941, 0.9966254047487083, 0.9880504910812913, 0.9903931096164952, 0.9926919560137727, 0.9872426580218356, 0.9989564744184013, 0.9920860674484671, 0.9810684441392946, 0.9884931835335041, 0.9943018511699803, 0.996706507594679, 0.9702487886653696, 0.9991833222049582, 0.9851797054615521, 0.9846592085554005, 0.973322485844787, 0.0009630281561913296, 0.9976971698142174, 0.9960793016631645, 0.9988996303578136, 0.9981529237906721, 0.9913699710140117, 0.9243836968184981, 0.07503114422228069, 0.9832211253544267, 0.9468724236948242, 0.02007723356328538, 0.9770920334132218, 0.991235670747872, 0.9975472836471345, 0.9929635759685963, 0.995444050476217, 0.9878315738086766, 0.9924327008443723, 0.9872847027935836, 0.9839224330890283, 0.9936244188203711, 0.9968422361807558, 0.9989993483453738, 0.9794689190216829, 0.9986941773829775, 0.0013060516705095608, 0.9980073875076404, 0.6419326375373239, 0.3576481837707947, 0.2888108688833777, 0.7110820170307123, 0.9991815545572377, 0.9864381205207239, 0.999145850055595, 0.992048863956682, 0.9988437605680224, 0.979407991116422, 0.9941600815877052, 0.9988165351799467, 0.9819907645417655, 0.9832737311282452, 0.016563569743354822, 0.9583683996080284, 0.21253176309245464, 0.7865661512580564, 0.9857362491811458, 0.986815087254595, 0.09368105898069676, 0.9055835701467354, 0.6325533891911332, 0.365741770053641, 0.9960314746178343, 0.997344450809054, 0.9954401311021245, 0.9991133020662281, 0.9822818230830592, 0.992733929943568], \"Term\": [\"able\", \"accessible\", \"act\", \"actually\", \"also\", \"always\", \"amazing\", \"annoying\", \"around\", \"arrogant\", \"art\", \"assign\", \"back\", \"bad\", \"base\", \"beware\", \"book\", \"bore\", \"bring\", \"buy\", \"care\", \"career\", \"catch\", \"challenge\", \"chapter\", \"child\", \"class\", \"classroom\", \"college\", \"come\", \"comment\", \"communicate\", \"complete\", \"confuse\", \"cool\", \"course\", \"course\", \"creativity\", \"day\", \"definitely\", \"different\", \"easily\", \"easy\", \"effort\", \"english\", \"enjoy\", \"especially\", \"even\", \"ever\", \"excellent\", \"expect\", \"fairly\", \"far\", \"favorite\", \"feedback\", \"fine\", \"fun\", \"funny\", \"funny\", \"get\", \"give\", \"go\", \"good\", \"good\", \"grade\", \"great\", \"half\", \"hard\", \"hate\", \"hear\", \"help\", \"help\", \"helpful\", \"helpful\", \"highly\", \"highly_recommend\", \"hilarious\", \"history\", \"idea\", \"improve\", \"incredible\", \"interested\", \"interesting\", \"issue\", \"job\", \"know\", \"lab\", \"lady\", \"language\", \"learn\", \"leave\", \"lecture\", \"lecturer\", \"lesson\", \"life\", \"life\", \"look\", \"lot\", \"love\", \"make\", \"material\", \"material\", \"math\", \"meet\", \"midterm\", \"money\", \"motivating\", \"motivating\", \"motivating\", \"motivating\", \"motivating\", \"movie\", \"much\", \"much\", \"need\", \"never\", \"new\", \"nice\", \"nursing\", \"obviously\", \"old\", \"opinion\", \"other\", \"paper\", \"passionate\", \"patience\", \"pay_attention\", \"people\", \"person\", \"personality\", \"point\", \"power_point\", \"probably\", \"professional\", \"professor\", \"professor\", \"project\", \"question\", \"read\", \"ready\", \"really\", \"really\", \"relevant\", \"requirement\", \"rude\", \"rude\", \"school\", \"see\", \"seem\", \"simple\", \"skip\", \"smart\", \"soon\", \"spanish\", \"speech\", \"spend\", \"student\", \"suffer\", \"take\", \"take\", \"talk\", \"teach\", \"teach\", \"teacher\", \"teacher\", \"test\", \"thank\", \"think\", \"thought\", \"time\", \"top\", \"topic\", \"tough\", \"unclear\", \"understand\", \"understand\", \"view\", \"want\", \"want\", \"waste\", \"watch\", \"way\", \"way\", \"well\", \"well\", \"willing\", \"woman\", \"wonderful\", \"work\", \"writing\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [5, 2, 1, 3, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el912761402243628538722351941816\", ldavis_el912761402243628538722351941816_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el912761402243628538722351941816\", ldavis_el912761402243628538722351941816_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el912761402243628538722351941816\", ldavis_el912761402243628538722351941816_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "4      0.357133 -0.184677       1        1  61.431291\n",
       "1      0.122830  0.331486       2        1  18.468551\n",
       "0     -0.173614 -0.134502       3        1  11.017355\n",
       "2     -0.152978 -0.003638       4        1   4.592845\n",
       "3     -0.153372 -0.008669       5        1   4.489958, topic_info=              Term         Freq        Total Category  logprob  loglift\n",
       "1            class  5449.000000  5449.000000  Default  30.0000  30.0000\n",
       "51       professor  1038.000000  1038.000000  Default  29.0000  29.0000\n",
       "4            great  1032.000000  1032.000000  Default  28.0000  28.0000\n",
       "12         teacher  1416.000000  1416.000000  Default  27.0000  27.0000\n",
       "55         student   981.000000   981.000000  Default  26.0000  26.0000\n",
       "...            ...          ...          ...      ...      ...      ...\n",
       "49     personality    27.087629    27.827914   Topic5  -5.1378   3.0764\n",
       "50    professional    23.916054    24.657809   Topic5  -5.2623   3.0728\n",
       "1005     obviously    23.545991    24.290257   Topic5  -5.2779   3.0722\n",
       "769    requirement    22.485502    23.234387   Topic5  -5.3240   3.0706\n",
       "179    power_point    22.556630    23.345995   Topic5  -5.3208   3.0689\n",
       "\n",
       "[203 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "245       3  0.997101        able\n",
       "1346      4  0.977823  accessible\n",
       "926       4  0.977481         act\n",
       "56        2  0.996979    actually\n",
       "71        1  0.998309        also\n",
       "...     ...       ...         ...\n",
       "164       2  0.997344       woman\n",
       "314       2  0.995440   wonderful\n",
       "38        1  0.999113        work\n",
       "296       5  0.982282     writing\n",
       "421       4  0.992734        year\n",
       "\n",
       "[191 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[5, 2, 1, 3, 4])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adea540253e8e8f708a1ef36fc3af2830fee8642e0041a914a62b471ba922451"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
